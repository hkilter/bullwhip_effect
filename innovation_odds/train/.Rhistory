map(database="world", col="#cccccc")
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[13], voip$Longitude[i])
lats <- c(voip$Latitude[13], voip$Latitude[i])
lines(lngs, lats, col="#ffb90f", lwd=2)}
map(database="world", col="#cccccc")
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[10], voip$Longitude[i])
lats <- c(voip$Latitude[10], voip$Latitude[i])
lines(lngs, lats, col="#ff4040", lwd=2)}
map(database="world", col="#cccccc")
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[27], voip$Longitude[i])
lats <- c(voip$Latitude[27], voip$Latitude[i])
lines(lngs, lats, col="#bb4cd4", lwd=2)}
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[15], voip$Longitude[i])
lats <- c(voip$Latitude[15], voip$Latitude[i])
lines(lngs, lats, col="#98f55f", lwd=2)}
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[10], voip$Longitude[i])
lats <- c(voip$Latitude[10], voip$Latitude[i])
lines(lngs, lats, col="#ff4040", lwd=2)}
for(i in 2: length(voip$Longitude) -1) {
lngs <- c(voip$Longitude[13], voip$Longitude[i])
lats <- c(voip$Latitude[13], voip$Latitude[i])
lines(lngs, lats, col="#ffb90f", lwd=2)}
library(fpp)
beer <- aggregate(ausbeer)
fix(beer)
plot(forecast(beer))
diskcost <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disk_cost_ts.csv")
diskcost.ts <- ts(diskcost, frequency=1)
fix(diskcost.ts)
plot(forecast(diskcost.ts))
View(diskcost)
diskcost <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disk_cost_ts.csv", Header=FALSE)
diskcost <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disk_cost_ts.csv", header=FALSE)
View(diskcost)
fix(beer)
fix(beer)
diskcost<- diskcost$V2
fix(diskcost)
diskcost.ts <- ts(diskcost, frequency=1, start = c(1956, 1), class = "ts")
fix(diskcost.ts)
plot(forecast(diskcost.ts))
forecast(diskcost.ts)
diskcost <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disk_cost_ts.csv", header=FALSE)
diskcost<- diskcost$V2
diskcost.ts <- ts(diskcost, frequency=1, start = c(1956, 1), class = "ts")
plot(forecast(diskcost.ts))
forecast(diskcost.ts)
fix(diskcost.ts)
applrev <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Apple_base_ts.csv", header=FALSE)
View(applrev)
applrev <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Apple_base_ts.csv", header=TRUE)
View(applrev)
applrev.lm <- lm(formula=Revenue~iPads+iPhones+iPods+Macs,data =applrev)
summary(applrev.lm)
iphonerev.ts < ts(applrev$iPhones,frequency=4, start=c(2008, 2), class="ts")
iphonerev.ts <- ts(applrev$iPhones,frequency=4, start=c(2008, 2), class="ts")
plot(forecast(iphonerev.ts))
fix(iphonerev.ts)
iphonerev.ts <- ts(applrev$iPhones,frequency=4, start=c(2008, 4), class="ts")
fix(iphonerev.ts)
iphonerev.ts <- ts(applrev$iPhones,frequency=4, start=c(2008, 2), class="ts")
forecast(iphonerev.ts)
ipadsales.ts <- ts(applrev$iPads[10:16],frequency=4, start=c(2010,3),class="ts")
plot(forecast(ipadsales.ts))
forecast(ipadsales.ts)
applmargin.ts <- ts(applrev$Gross.Margin,frequency=4,start=c(2008,2),class="ts")
plot(forecast(applemargin.ts))
plot(forecast(applmargin.ts))
appleps.ts <- ts(applrev$EPS,frequency=4,start=c(2008,2),class="ts")
plot(forecast(appleps.ts))
forecast(applmargin.ts)
forecast(appleps.ts)
apple_rev <- ts(applrev$Revenue,frequency=4,start=c(2008,2),class="ts")
forecast(apple_rev)
map(database="state")
library(maps)
map(database="state")
blockbuster <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Blockbuster_USA-CAN.csv", header=FALSE)
names(blockbuster) <- c("Longitude","Latitude","Company","Address")
netflix <-  read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\netflix_dist_geo.csv")
names(netflix)<- c("Address","City","State","ZipCode","Latitude","Longitude)
names(netflix)<- c("Address","City","State","ZipCode","Latitude","Longitude")
#load relevent map
names(netflix)<- c("Address","City","State","ZipCode","Latitude","Longitude")
View(netflix)
symbols(blockbuster$Longitude, blockbuster$Latitude, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(blockbuster$Latitude)),
inches=0.05, add=TRUE)
symbols(netflix$Longitude, netflix$Latitude, bg="#ff4040", fg="#ffffff",
lwd=0.5, circles=rep(1, length(netflix$Latitude)),
inches=0.05, add=TRUE)
symbols(netflix$Longitude, netflix$Latitude, bg="#FF0000", fg="#ffffff",
lwd=0.5, circles=rep(1, length(netflix$Latitude)),
inches=0.05, add=TRUE)
usrand <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\10krandom_geocodes.csv")
View(usrand)
View(usrand)
names(usrand)<- c("Latitude","Longitude")
View(usrand)
symbols(usrand$Longitude, usrand$Latitude, bg="#FF0000", fg="#ffffff",
lwd=0.5, circles=rep(1, length(usrand$Latitude)),
inches=0.05, add=TRUE)
install.packages("rattle")
library(forecast)
northfield <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\northfield_singlefamily_ts.csv", header=FALSE)
View(northfield)
View(northfield)
housesqft.ts <- ts(northfield,frequency=12, start=c(2011,4), class="ts")
plot(forecast(housesqft.ts))
faribault < - read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\faribault_sales_ts.csv", header=FALSE))
faribault < - read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\faribault_sales_ts.csv", header=FALSE)
faribault < - read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\faribault_sales_ts.csv", header=FALSE)
faribault <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\faribault_sales_ts.csv", header=FALSE)
faribaultsqft.ts <- ts(faribault, frequency=12,start=c(6,2011),class ="ts")
plot(forecast(faribaultsqft.ts))
library(forecast)
plot(forecast(faribaultsqft.ts))
faribaultsqft.ts <- ts(faribault, frequency=12,start=c(2011,6),class ="ts")
plot(forecast(faribaultsqft.ts))
forecast(faribaultsqft.ts)
bbyrev <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\BBY_rev_ts.csv", header=TRUE)
bbyrev.tx <- ts(bbyrev,frequency=4, start=c(2007,4),class="ts")
bbyrev.ts <- ts(bbyrev,frequency=4, start=c(2007,4),class="ts")
library(forecast)
plot(forecast(bbyrev.ts))
bby <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\bby_base.csv", header=TRUE)
View(bby)
bby <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\bby_base.csv", header=TRUE)
View(bby)
revchage.lm <- lm(formula=Revenue_change~Store.size+number.of.stores+cust_service+overall+Price.Index)
revchange.lm <- lm(formula=Revenue_change~Store.size+number.of.stores+cust_service+overall+Price.Index)
View(bby)
revchange.lm <- lm(formula=Revenuechg_pct~Store.size+number.of.stores+cust_service+overall+Price.Index)
names(bby) <- c("company","cust_service","overall","store_num","store_size", 'store_size_index",""price_index", "index_pct","rev_sqft","revchg_pct","revchg")
names(bby) <- c("company","cust_service","overall","store_num","store_size", 'store_size_index","price_index", "index_pct","rev_sqft","revchg_pct","revchg")
names(bby) <- c("company","cust_service","overall","store_num","store_size","store_size_index","price_index", "index_pct","rev_sqft","revchg_pct","revchg")
revchange.lm <-lm(formula=revchg~store_size+store_num+cust_service+overall+price_index)
View(bby)
bby <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\bby_base.csv", header=TRUE)
names(bby) <- c("company","cust_service","overall","store_num","store_size","store_size_index","price_index", "index_pct","rev_sqft","revchg_pct","revchg")
revchange.lm <-lm(formula=revchg~store_size+store_num+cust_service+overall+price_index)
revchange.lm <-lm(formula=revchg~store_size+store_num+cust_service+overall+price_index, data=bby)
summary(revchange.lm)
bbyrev <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\BBY_rev_ts.csv", header=TRUE)
bby <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\bby_base.csv", header=TRUE)
View(bby)
revchange.lm <-lm(formula=Revenue_change~Store.size+Stores+price_index, data=bby)
revchange.lm <-lm(formula=Revenue_change~Store.size+Stores+Price.Index, data=bby)
summary(revchange.lm)
revloc.lm <-lm(formula=RevChange_per_location~service+overall+, data=bby)
revloc.lm <-lm(formula=RevChange_per_location~service+overall, data=bby)
summary(revloc.lm)
bby <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\bby_base.csv", header=TRUE)
revloc.lm <-lm(formula=RevChange_per_location~service+overall, data=bby)
summary(revloc.lm)
disksize <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Drive_size_ts.csv", header=TRUE)
View(disksize)
disksize.ts <- ts(disksize$Size_inches, frequency=1, start = c(1956, 1), class = "ts")
plot(disksize.ts)
plot(disksize.ts, ylab="disksize(inches)")
plot(disksize.ts, ylab="disksize(inches)", main="Drive Size Over Time(1956-2012)")
plot(disksize.ts, ylab="Disk Size(inches)", main="Drive Size to Consumers Over Time(1956-2012)")
plot(disksize.ts, ylab="Disk Size(inches)", main="Drive Size to Consumers Over Time(1956-2012)", col="blue")
View(disksize)
disksize.ts <- ts(disksize$Size_inches[27:61], frequency=1, start = c(1984, 1), class = "ts")
plot(disksize.ts, ylab="Disk Size(inches)", main="Drive Size to Consumers Over Time(1956-2012)", col="blue")
plot(disksize.ts, ylab="Disk Size(inches)", main="Drive Size to Consumers Over Time(1984-2012)", col="blue")
pinterest <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Pinterest_users_ts.csv", header=TRUE)
pinterest <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Pinterest_users_ts.csv", header=TRUE)
View(pinterest)
pinterest <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Pinterest_users_ts.csv", header=FALSE)
View(pinterest)
pinterest.ts <- ts(pinterest$V2,frequency=12, start(2010,3),class="ts")
plot(forecast(pinterest.ts, h=36))
library(forecast)
plot(forecast(pinterest.ts, h=36))
disksize <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Drive_size_ts.csv", header=TRUE)
View(disksize)
postage <- read.csv("http://datasets.flowingdata.com/us-postage.csv", sep=",", header=TRUE)
disksize <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\Drive_size_ts.csv", header=TRUE)
View(disksize)
plot(disksize$Year, disksize$Size_inches, type="s", main="Hard disk size 1956-2011", xlab="Year",ylab="Size(inches)"
)
plot(disksize$Year, disksize$Size_inches, type="s", main="Hard disk size 1956-2011", xlab="Year",ylab="Size(inches)",col=blue)
plot(disksize$Year, disksize$Size_inches, type="s", main="Hard disk size 1956-2011", xlab="Year",ylab="Size(inches)",col="blue")
install.packages("calibrate")
textxy(disksize$Year, disksize$Size_inches,disksize$Company)
library(calibrate)
textxy(disksize$Year, disksize$Size_inches,disksize$Company)
textxy(disksize$Year, disksize$Size_inches,disksize$Company, dcol="green" cx = .7)
textxy(disksize$Year, disksize$Size_inches,disksize$Company, dcol="green", cx = .7)
plot(disksize$Year, disksize$Size_inches, type="s", main="Hard disk size 1956-2011", xlab="Year",ylab="Size(inches)",col="blue")
textxy(disksize$Year, disksize$Size_inches,disksize$Company, cx = .7)
plot(disksize$Year, disksize$Size_inches, type="s", main="Hard disk size 1956-2011", xlab="Year",ylab="Size(inches)",col="blue")
textxy(disksize$Year, disksize$Size_inches,disksize$Company, cx = 1.0)
library(forecast)
forecast::forecast.default
forecast:::forecast.default
edit(forecast)
forecast:::forecast.formula
print(getAnywhere(forecast.class))
methods(forecast)
forecast:::forecast.ts.default
forecast:::forecast.HoltWinters
forecast:::forecast.ar
forecast:::forecast.Arima
forecast:::forecast.ets
forecast:::forecast.fracdiff
forecast:::forecast.lm
forecast:::forecast.stl
forecast:::forecast.StructTS
View(disksize)
View(disksize)
x <- c(88,5,12,13)
x
x<- c(x[1:3],168,x[4])
x
library(RColorBrewer)
View(hot_dog_places)
device <-read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\hardware_devices.csv", header=TRUE)
View(device)
View(device)
disruptive <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disruptive.csv", header=TRUE)
disruptive_range <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\disruptive_range.csv", header=TRUE)
disruptive <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive.csv", header=TRUE)
disruptive_range <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive_range.csv", header=TRUE)
View(disruptive)
View(disruptive_range)
disruptive_range <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive_range.csv", header=TRUE)
View(disruptive_range)
disruptive.lm <- lm(gain~ funding, data=disruptive)
summary(disruptive.lm)
disruptive_range.lm <- (gain~ funding, data=disruptive.range)
disruptive_range.lm <- (gain~ funding, data=disruptive_range)
disruptive_range.lm <- lm(gain~ funding, data=disruptive_range)
summary(disruptive_range.lm)
disruptive <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive.csv", header=TRUE)
disruptive <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive.csv", header=TRUE)
disruptive_range <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\disruptive_range.csv", header=TRUE)
disruptive.lm <- lm(gain~ funding, data=disruptive)
disruptive_range.lm <- lm(gain~ funding, data=disruptive_range)
plot(disruptive.lm)
plot(disruptive_range.lm)
library(ggplot2)
p <- ggplot2(disruptive, aes(funding, gain))
p <- ggplot(disruptive, aes(funding, gain))
p
View(disruptive)
View(disruptive_range)
p <- ggplot(disruptive_range, aes(funding,gain))
p
p <- ggplot(disruptive_range, aes(x =funding,y=gain))
p
plot(p)
m <- ggplot(disruptive, aes(x=funding))
m
m + geom_histogram(aes(y = ..density..)) + geom_density()
p <- ggplot(disruptive_range, aes(x =funding,y=gain))
p + geom_point()
p <- ggplot(disruptive, aes(x =funding,y=gain))
p + geom_point()
View(hot_dog_places)
View(hot_dog_places)
hot_dog_places <- read.csv("C:\Documents and Settings\Luke\Desktop\Programming\R\2007to2012funding.csv", sep=",", header=TRUE)
hot_dog_places <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\2007to2012funding.csv", sep=",", header=TRUE)
View(hot_dog_places)
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011",
View(hot_dog_places)
View(hot_dog_places)
View(hot_dog_places)
View(hot_dog_places)
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011",
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011","2012")
)
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011","2012")
hot_dog_matrix <- as.matrix(hot_dog_places)
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 200),
)
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 200),
xlab="Year", ylab="2007 to 2012",
main="Startup funding, 2007-2012")
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 1000000000),
xlab="Year", ylab="2007 to 2012",
main="Startup funding, 2007-2012")
hot_dog_places <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\2007to2012funding.csv", sep=",", header=TRUE)
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011","2012")
hot_dog_matrix <- as.matrix(hot_dog_places)
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 1000000000),
xlab="Year", ylab="2007 to 2012",
main="Startup funding, 2007-2012")
hot_dog_places <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\2007to2012funding.csv", sep=",", header=TRUE)
names(hot_dog_places) <- c("2007", "2008", "2009", "2010", "2011","2012")
hot_dog_matrix <- as.matrix(hot_dog_places)
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 1000000000),
xlab="Year", ylab="Millions of Dollars in Funding",
main="Startup funding, 2007-2012")
barplot(hot_dog_matrix, border=NA, space=0.25, ylim=c(0, 1000),
xlab="Year", ylab="Millions of Dollars in Funding",
main="Startup funding, 2007-2012")
library(maps)
ipo_loc <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\company_locations_ipo2.csv", header=TRUE)
ipo_loc <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\company_location_ipo2.csv", header=TRUE)
View(ipo_loc)
ipo_loc <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\company_location_ipo2.csv", sep='\t', header=TRUE)
View(ipo_loc)
map(database="world", col="#cccccc")
map(database="state")
#map company ipo locations
symbols(ipo_loc$longitude, ipo_loc$latitude, bg="#FF0000", fg="#ffffff",
lwd=0.5, circles=rep(1, length(usrand$Latitude)),
inches=0.05, add=TRUE)
symbols(ipo_loc$longitude, ipo_loc$latitude, bg="#FF0000", fg="#ffffff",
lwd=0.5, circles=rep(1, length(ipo_loc$latitude)),
inches=0.05, add=TRUE)
map(database="world", fill = FALSE, col = "#cccccc")
symbols(ipo_loc$longitude, ipo$latitude,
circles=sqrt((ipo_loc$amount)/100000000000), add=TRUE,
inches=0.15, bg="#93ceef", fg="#ffffff")
circles=sqrt((ipo_loc$amount)), add=TRUE,
symbols(ipo_loc$longitude, ipo$latitude,
circles=sqrt(ipo_loc$amount), add=TRUE,
inches=0.15, bg="#93ceef", fg="#ffffff")
ipo_loc <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\company_location_ipo2.csv", sep='\t', header=TRUE)
ymbols(ipo_loc$longitude, ipo$latitude,
circles=sqrt(ipo_loc$amount/100000), add=TRUE,
inches=0.15, bg="#93ceef", fg="#ffffff")
symbols(ipo_loc$longitude, ipo$latitude,
circles=sqrt(ipo_loc$amount/100000), add=TRUE,
inches=0.15, bg="#93ceef", fg="#ffffff")
symbols(ipo_loc$longitude, ipo_loc$latitude,
circles=sqrt(ipo_loc$amount/100000), add=TRUE,
inches=0.15, bg="#93ceef", fg="#ffffff")
map(database="world", fill = FALSE, col = "#cccccc")
View(ipo_loc)
map(database="world", col="#cccccc")
#plot geocoded locations on map in US
symbols(ipo_loc$longitude, ipo_loc$latitude, bg="#99FF33", fg="#ffffff",
lwd=0.5, circles=rep(1, length(ipo_loc$latitude)),
inches=0.05, add=TRUE)
w <- function(x) return(x+1)
w
w(u)
u <-c(5,2,8)
w(u)
library(maps)
area.map(m, c("Minnesota"))
m = map("state", fill = TRUE, plot = FALSE)
area.map(m, c("Minnesota"))
map(database="state")
walmart <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\Programming\\R\\walmart_loc_2012.csv", header=FALSE)
View(walmart)
map(database="state")
symbols(walmart$V1, walmart$V2, bg="#99FF33", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
symbols(walmart$V1, walmart$V2, bg="#99FF33", fg="#0000CD",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(database="state", col="#cccccc")
symbols(walmart$V1, walmart$V2, bg=#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(database="world", col="#cccccc")
map(database="state")
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ff4040",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(database="state")
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(’state’, region = c(’minnesota’))
map(database=’state’, region = c(’minnesota’))
map(database="state", region = c("minnesota"))
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(database="state", region = c("minnesota","wisconsin"))
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
map(database="state", region = c("minnesota","wisconsin", "iowa"))
symbols(walmart$V1, walmart$V2, bg="#0000CD", fg="#ffffff",
lwd=0.5, circles=rep(1, length(walmart$V1)),
inches=0.05, add=TRUE)
g < c("M","F","F","I", "M","M","F")
g <- c("M","F","F","I", "M","M","F")
ifelse(g=="M",1,ifelse(g =="F"),2,3)
ifelse(g=="M",1,ifelse(g =="F",2,3))
library('tm')
library('ggplot2')
data.path <- file.path("..", "03-Classification", "data")
easyham.path <- file.path(data.path, "easy_ham")
parse.email <- function(path) {
full.msg <- msg.full(path)
date <- get.date(full.msg)
from <- get.from(full.msg)
subj <- get.subject(full.msg)
msg <- get.msg(full.msg)
return(c(date, from, subj, msg, path))
}
msg.full <- function(path) {
con <- file(path, open="rt", encoding="latin1")
msg <- readLines(con)
close(con)
return(msg)
}
get.from <- function(msg.vec){
from <- msg.vec[grepl("From:", msg.vec)]
from <- strsplit(from, '[":<>]')[[1]]
from <- from[which(from !="" & from != " ")]
return(from[grepl("@", from)][1])
}
get.msg <- function(msg.vec){
msg <- msg.vec[seq(which(msg.vec == "")[1] +1, length(msg.vec), 1)]
return(paste(msg, collapse="\n"))
}
get.subject <- function(msg.vec)
{
subj <- msg.vec[grepl("Subject: ", msg.vec)]
if(length(subj) > 0)
{
return(strsplit(subj, "Subject: ")[[1]][2])
}
else
{
return("")
}
}
get.date <- function(msg.vec)
{
date.grep <- grepl("^Date: ", msg.vec)
date.grep <- which(date.grep == TRUE)
date <- msg.vec[date.grep[1]]
date <- strsplit(date, "\\+|\\-|: ")[[1]][2]
date <- gsub("^\\s+|\\s+$", "", date)
return(strtrim(date, 25))
}
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.parse <- lapply(easyham.docs,
function(p) parse.email(file.path(easyham.path, p)))
ehparse.matrix <- do.call(rbind, easyham.parse)
allparse.df <- data.frame(ehparse.matrix, stringsAsFactors = FALSE)
names(allparse.df) <- c("Date", "From.EMail", "Subject", "Message", "Path")
names(allparse.df) <- c("Date", "From.EMail", "Subject", "Message", "Path")
library(forecast)
forecast
tseries:::default
tseries::default
tseries:default
forecast:default
forecast:::default
forecast::default
forecast
library(forecast)
forecast::forecast.formula
forecast::forecast
forecast:::forecast.formula
library(fpp)
fpp:::forecast.formula
fpp:forecast.formula
fpp::forecast
forecast:::forecast
print(forecast.class)
print(getAnywhere(forecast.class))
print(getAnywhere(forecast))
forecast
print forecast
print(forecast)
forecast:::forecast.class
forecast:::forecast.formula
forecast:::rev.default
getMethod(forecast)
getMethod("forecast")
applrev <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\WP_2010_2012_ts.csv", header=TRUE)
View(applrev)
twolves_wp <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\WP_2010_2012_ts.csv", delimiter='\t', header=TRUE)
twolves_wp <- read.csv("C:\\Documents and Settings\\Luke\\Desktop\\WP_2010_2012_ts.csv", sep="\t", header=TRUE)
View(twolves_wp)
twolves_wins_produced.ts <- ts(twolves_wp$WP_Diff, frequency=82, start = c(2010, 1), class = "ts")
fix(twolves_wins_produced.ts)
plot(forecast(twolves_wins_produced.ts))
library(forecast)
forecast(twolves_wins_produced.ts)
twolves_wins_produced.ts <- ts(twolves_wp$WP_Diff, frequency=41, start = c(2010, 1), class = "ts")
forecast(twolves_wins_produced.ts)
plot(forecast(twolves_wins_produced.ts))
setwd('C:\\Documents and Settings\\Luke\\Desktop\\green_banana_citations\\train')
read.csv("diffusion_revenue_time.csv",header =TRUE)
tech_train <- read.csv("diffusion_revenue_time.csv",header =TRUE)
View(tech_train)
library(rpart)
tech_train.model <- rpart(reached_500_million<-Timeto50m+Timeof50m+X2008.Revenue.Multiple +Industry+category+X2nd_category+Available.years	percent_time_used, data=tech_train)
tech_train.model <- rpart(reached_500_million<-Timeto50m+Timeof50m+X2008.Revenue.Multiple +Industry+category+X2nd_category+Available.years	+percent_time_used, data=tech_train)
View(tech_train)
tech_train.model <- rpart(reached_500_million<-Timeto50m+Timeof50m+Industry+category+X2nd_category+Available.years+percent_time_used, data=tech_train)
tech_train.model <- rpart(reached_500_million~Timeto50m+Timeof50m+Industry+category+X2nd_category+Available.years+percent_time_used, data=tech_train)
tech_train.model
plot(tech_train.model, uniform=TRUE, compress=TRUE, lty=3, branch=0.7)
text(tech_train.model, all=TRUE,digits=7, use.n=TRUE, cex=0.4, xpd=TRUE)
text(tech_train.model, all=TRUE,digits=7, use.n=TRUE, cex=0.7, xpd=TRUE)
plot(tech_train.model, uniform=TRUE, compress=TRUE, lty=3, branch=0.7)
text(tech_train.model, all=TRUE,digits=7, use.n=TRUE, cex=0.8, xpd=TRUE)
